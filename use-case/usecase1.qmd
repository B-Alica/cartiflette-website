---
title: "Associer des arrondissements √† des donn√©es communales avec cartiflette"
output: true
number-sections: true
code-annotations: hover
---


::: {.important}
Cette page est un _work in progress_! Des exemples dans d'autres langages que `Python` {{< fa brands python >}} viendront ult√©rieurement. 

Cette page fait partie d'une s√©rie de tutoriels illustrant les fonctionnalit√©s de `cartiflette`. Pour retrouver la liste de ceux-ci, c'est [ici](/use-case/index.qmd)
:::


Ce tutoriel vise √† illustrer un cas d'usage classique de `cartiflette` : __r√©cup√©rer de mani√®re flexible un fonds de carte m√©langeant les niveaux administratifs diff√©rents que sont [communes]{.yellow} et [arrondissements]{.yellow}__.  

Ce besoin classique est illustr√© √† travers la construction d'une carte de la disponibilit√© de v√©libs dans la petite couronne parisienne (Paris intra-muros et d√©partements limitrophes). 
L'objectif de ce tutoriel est de faire une carte du nombre de v√©libs au km¬≤ dans chaque arrondissement de Paris intra-muros et chaque commune de la petite couronne. Il illustre, pas √† pas, la mani√®re dont `cartiflette` simplifie la cr√©ation d'une carte comme celle-ci:




::: {.tip}
## Pourquoi utiliser `cartiflette` pour ce type de besoins ?

- Beaucoup [moins de ligne de code]{.yellow} √† √©crire :
    + R√©duit le temps n√©cessaire avant d'obtenir une carte exploratoire, ce qui permet de se concentrer sur la construction de celle-ci plut√¥t que les √©tapes ant√©rieures
    + R√©duit la difficult√© √† mettre √† jour le code ;
- [Moins de bande passante]{.yellow} et d'espace disque utilis√© car seule la donn√©e n√©cessaire est t√©l√©charg√©e ;
- [Moindre besoin d'expertise en SIG]{.yellow} car la librairie fournit un `GeoDataFrame` pr√™t √† l'emploi ce qui ne n√©cessite pas une connaissance pointue dans le domaine (syst√®me de projection, format _shapefile_, etc.) ;
- [Moins de risque d'erreur]{.yellow} que lorsqu'on fait soi-m√™me la combinaison de sources √† des niveaux administratifs diff√©rents (accoler le masque des arrondissements √† celui des communes limitrophes n√©cessite beaucoup de pr√©cautions) ;
- [B√©n√©ficier de m√©tadonn√©es suppl√©mentaires]{.yellow} sur les communes que les fonds de carte `AdminExpress`

:::


::: {.note}
## Et Lyon et Marseille ?

`cartiflette` fournit le m√™me d√©coupage par arrondissement pour les villes de Lyon et Marseille. Pour cela, il suffit de demander une zone g√©ographique englobant Lyon et Marseille, par exemple le d√©partement du Rh√¥ne ou la r√©gion Provence Alpes C√¥te d'Azur. 

:::


::: {.caution collapse="true"}
## Pour en apprendre plus sur le traitement de donn√©es g√©ographiques avec `Python` {{< fa brands python >}}

Ce tutoriel pr√©suppose une connaissance minimale de l'√©cosyst√®me `Python` pour le traitement de donn√©es spatiales. Pour se familiariser √† celui-ci, vous pouvez consulter ce cours d'[Introduction √† `Python` {{< fa brands python >}} pour la _data science_](https://pythonds.linogaliana.fr/content/manipulation/03_geopandas_intro.html) de l'ENSAE ParisTech. 

:::


# Pr√©liminaire: r√©cup√©ration des localisations des stations

Les donn√©es V√©lib que nous utiliserons sont r√©cup√©rables directement avec `GeoPandas`. Il s'agit de la capacit√© et la localisation des stations sous la forme de latitude-longitude[^WGS]

[^WGS]: Le syst√®me de coordonn√©es WGS84 (_World Geodetic System 1984_) est un syst√®me de r√©f√©rence g√©od√©sique utilis√© pour repr√©senter les positions g√©ographiques sur la Terre. Ce syst√®me est utilis√© par la plupart des applications GPS et des fournisseurs de tuiles vectorielles comme `OpenStreetMap`.


```{python}
import geopandas as gpd

velib_data = "https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr"
stations = gpd.read_file(velib_data)
```

Ces donn√©es prennent la forme suivante:

```{python}
#| echo: false
stations.head(2)
```

et peuvent √™tre localis√©es sur une carte de la mani√®re suivante:

```{python}
#| output: false
#| code-fold: true
#| code-summary: "Voir le code pour g√©n√©rer la carte interactive üëáÔ∏è"
import folium
from folium.plugins import MarkerCluster

# 1. Calcul du centre de la carte et des bornes sw et ne
stations['lon'] = stations.geometry.x
stations['lat'] = stations.geometry.y
center = stations[['lat', 'lon']].mean().values.tolist()
sw = stations[['lat', 'lon']].min().values.tolist()
ne = stations[['lat', 'lon']].max().values.tolist()

m = folium.Map(location=center, tiles='OpenStreetMap')
marker_cluster = MarkerCluster().add_to(m) #<1>

# Add the markers to the MarkerCluster
for i in range(len(stations)):
    folium.Marker(
        location=[stations.iloc[i]['lat'], stations.iloc[i]['lon']],
        popup=stations.iloc[i]['name']
    ).add_to(marker_cluster)

# Fit the map bounds to the markers
m.fit_bounds([sw, ne])
m
```
1. Cette fonctionnalit√© permet d'avoir une carte interactive avec zoom progressifs car le nombre de stations est important ce qui ralentirait la carte de toutes les afficher 


```{python}
#| echo: false
m
```

<br>
Nous allons avoir besoin des contours d'arrondissements et de communes pour deux raisons:

- Localiser les stations √† ce niveau d'analyse par le biais d'une [jointure spatiale](https://geopandas.org/en/stable/gallery/spatial_joins.html) avant de pouvoir les agr√©ger √† ce niveau ;
- Repr√©senter ces donn√©es sur une carte pr√©sentant Paris intra-muros et les villes limitrophes participant au syst√®me V√©lib.


# R√©cup√©rer les contours administratifs officiels l'IGN via `cartiflette`

## La r√©cup√©ration des donn√©es utilisant `cartiflette`

```{python}
#| echo: false
import time
start_time_cartiflette = time.time()
```

Les contours administratifs officiels sont produits par l'[IGN](https://www.ign.fr/) et utilisent le [code officiel g√©ographique (COG)](https://www.insee.fr/fr/metadonnees/source/serie/s2084) (liste officielle des entit√©s administratives) produit par l'Insee. 

La source la plus simple pour r√©pondre √† notre besoin est [`AdminExpress EXPRESS-COG-CARTO-TERRITOIRE`](https://geoservices.ign.fr/adminexpress). En l'occurrence, seuls quelques espaces nous int√©ressent: ce sont les villes et arrondissements de la petite couronne parisienne (d√©partements 75, 92, 93 et 94). 

Avec la fonction `carti_download`, l'import de ces donn√©es est assez transparent:


::: {#lst-cartiflette-example lst-cap="Example d'utilisation de cartiflette"}

```{python}
#| code-line-numbers: true
from cartiflette import carti_download

# 1. Fonds communaux
contours_villes_arrt = carti_download(
    values = ["75", "92", "93", "94"],
    crs = 4326, #<1>
    borders="COMMUNE_ARRONDISSEMENT",
    filter_by="DEPARTEMENT", #<2>
    source="EXPRESS-COG-CARTO-TERRITOIRE",
    year=2022)

# 2. D√©partements 
departements = contours_villes_arrt.dissolve("INSEE_DEP") #<3>
```
1. 4326 est le code du syst√®me de repr√©sentation WGS84 (le m√™me que celui des donn√©es V√©lib). De futures d√©veloppement de `cartiflette` permettront de r√©cup√©rer des donn√©es avec d'autres projections, notamment les syst√®mes Lambert.
2. Ici on r√©cup√®re seulement des d√©partements, l'emprise la plus petite qui puisse satisfaire notre besoin. N√©anmoins, il serait possible d'obtenir les donn√©es √† une autre √©chelle g√©ographique, par exemple la r√©gion Ile de France, en sp√©cifiant les arguments `filter_by="DEPARTEMENT"` et `values="11"`.
3. La construction du fonds de carte `departements` se fait simplement avec la m√©thode `dissolve`. Il nous sera utile pour contextualiser la carte. 

:::

```{python}
#| echo: false
end_time_cartiflette = time.time()
```

`contours_villes_arrt` est un `GeoDataFrame` classique, il est donc possible d'appliquer √† celui-ci les m√©thodes usuelles de `GeoPandas` par exemple la m√©thode `dissolve` ci-dessus. Le masque obtenu pour notre carte est celui-ci

```{python}
contours_villes_arrt.plot()
```

Pour voir le code permettant d'obtenir un `GeoDataFrame` √©quivalent sans passer par `cartiflette`, vous pouvez vous rendre dans la partie [Comment faire sans `cartiflette` ?](#sans-cartiflette). La section [Bilan](#bilan) fournit quelques √©l√©ments de comparaison entre l'approche avec et celle sans `cartiflette` (temps de traitement, volume de donn√©es t√©l√©charg√©es, nombre de lignes de codes, etc.). 


## Le reste du travail apr√®s avoir utilis√© `cartiflette`

La suite du travail n'est pas li√© √† `cartiflette` mais est de la manipulation de donn√©es spatiales. 

Comme nous avons besoin de localiser les stations dans les arrondissements, nous faisons une jointure spatiale entre notre fonds de carte et nos donn√©es V√©lib

```{python}
stations_info = gpd.sjoin(
    stations, contours_villes_arrt, predicate="within"
)
```

Outre la localisation des stations au niveau communes ou arrondissement, cela permet d'ajouter une ribambelle de m√©tadonn√©es (des informations annexes) √† nos donn√©es initiales:

```{python}
#| echo: false
stations_info.head(2)
```

Le d√©compte des stations par communes et arrondissements se fait alors assez ais√©ment en utilisant la grammaire `Pandas`. Pour cela, il est possible d'utiliser la variable `INSEE_COG` construite par `cartiflette` pour consolider les codes communes des arrondissements et des communes[^inseeCOM]

[^inseeCOM]: La variable `INSEE_COM` correspond au code officiel g√©ographique au niveau communal. La valeur est donc identique pour les 20 arrondissements parisiens.  

```{python}
comptes = (
    stations_info
    .groupby("INSEE_COG")
    .agg({"capacity": "sum"})
    .reset_index()
)
```

Enfin, il ne reste plus qu'√† construire la variable d'int√©r√™t, ce qui n'est pas du travail li√© √† `cartiflette`:

```{python}
#| code-fold: true
#| code-summary: "D√©rouler üëáÔ∏è pour voir le code permettant pr√©parer la carte"
#| output: false
import pandas as pd

# Conversion des variables
contours_villes_arrt["INSEE_COG"] = contours_villes_arrt["INSEE_COG"].astype(str) #<1>
comptes["INSEE_COG"] = comptes["INSEE_COG"].astype(str) #<1>

# Jointure pour retrouver la dimension g√©ographique de nos donn√©es agr√©g√©es
comptes_velib_by_city_arrt = contours_villes_arrt.merge(
    comptes, how = "inner", on = "INSEE_COG"
)
comptes_velib_by_city_arrt['densite'] = comptes_velib_by_city_arrt['capacity']

# Cr√©ation des variables pour la taille de nos ronds proportionnels
df_points = comptes_velib_by_city_arrt.copy()

df_points["markersize"] = 12*df_points["densite"].div(comptes_velib_by_city_arrt.to_crs(2154).area.div(10**6).sum())

bins = [-float('inf'), 20, 100, 500, float('inf')]
labels = ["Moins de 20", "Entre 20 et 100", "Entre 100 et 500", "Plus de 500"]

df_points["markercolor"] = pd.cut(
    df_points['densite'], bins=bins, labels=labels, right=True
)

# Centre de nos cercles
df_points["geometry"] = df_points["geometry"].centroid
```
1. On force la conversion de la variable `INSEE_COG` en _string_ pour √©viter le type `object` de `Pandas` qui peut poser des probl√®mes lors des jointures. 

Finalement, on obtient la carte avec le code suivant

```{python}
#| code-fold: true
#| code-summary: "D√©rouler üëáÔ∏è pour voir le code permettant de faire la carte"
import matplotlib.pyplot as plt

ax = comptes_velib_by_city_arrt.plot(
    color="lightgray", edgecolor="grey", figsize=(7, 7), linewidth=0.4, alpha=0.3
)
df_points.plot(
    ax=ax,
    column="markercolor",
    markersize="markersize",
    alpha=0.7,  # categorical=False,
    legend=True,
    legend_kwds={"loc": "upper center", "ncol": 2, "bbox_to_anchor": (0.5, 0.05)},
    cmap="viridis",
)
departements.boundary.plot(ax=ax, edgecolor="black", alpha=0.3)
ax.axis("off")
ax.set(title="Densit√© de population dans la petite couronne")
ax.get_legend().set_title("Nombre de v√©lib par km¬≤")
plt.figtext(
    0.3,
    0.15,
    "Source: IGN - AdminExpress",
    wrap=True,
    horizontalalignment="center",
    fontsize=8,
    style="italic",
)
```

# Comment faire sans `cartiflette` ? {.sans-cartiflette}

```{python}
#| echo: false
start_time_no_cartiflette = time.time()
```

L'approche est nettement plus fastidieuse sans `cartiflette`. Pour obtenir les m√™mes donn√©es, pr√™tes √† l'emploi, cela passe par quatre √©tapes principales:

* 1Ô∏è‚É£ T√©l√©charger les donn√©es et les enregistrer sur le disque, en local.
* 2Ô∏è‚É£ D√©zipper la version t√©l√©charg√©e (le format est une archive 7z) et enregistrer l'arborescence obtenue sur le disque.
* 3Ô∏è‚É£ Importer les bons _shapefile_ dans `Python`.
* 4Ô∏è‚É£ Cr√©er le fonds de carte consolid√© en se restreignant aux d√©partements d'int√©r√™t pouis en retirant la commune de Paris et en y apposant, √† la place, les arrondissements.

La premi√®re √©tape consiste donc √† t√©l√©charger le fichier depuis le site de mise √† disposition de l'IGN. L'archive √©tant assez volumineuse, le code propos√© propose une barre de progr√®s pour s'assurer que le t√©l√©chargement progresse.

Le code √©tant assez long, il n'est pas apparent par d√©faut mais il suffit de cliquer ci-dessous:

::: {#lst-example-download-adminexpress lst-cap="1Ô∏è‚É£ Code pour t√©l√©charger les donn√©es"}


```{python}
#| code-fold: true
#| code-summary: "1Ô∏è‚É£ Code pour t√©l√©charger les donn√©es"
#| code-line-numbers: true
#| output: false

import os
import requests
import py7zr
from tqdm import tqdm

# Step 1: Download the file with progress bar
url = "https://data.geopf.fr/telechargement/download/ADMIN-EXPRESS-COG-CARTO/ADMIN-EXPRESS-COG-CARTO_3-1__SHP_WGS84G_FRA_2022-04-15/ADMIN-EXPRESS-COG-CARTO_3-1__SHP_WGS84G_FRA_2022-04-15.7z"
file_name = url.split("/")[-1]

def download_7z_archive(file_name):
    if os.path.exists(file_name) is False:
        # Streaming download with progress bar
        print("Downloading file...")
        response = requests.get(url, stream=True)
        total_size = int(response.headers.get('content-length', 0))

        with open(file_name, 'wb') as file, tqdm(
                desc=file_name,
                total=total_size,
                unit='iB',
                unit_scale=True,
                unit_divisor=1024,
            ) as bar:
            for chunk in response.iter_content(chunk_size=8192):
                size = file.write(chunk)
                bar.update(size)

        print(f"Downloaded {file_name}")
        return file_name
    else:
        print("File exists, please delete it before going further")

download_7z_archive(file_name)
```

:::


La deuxi√®me √©tape consiste √† d√©zipper la version t√©l√©charg√©e en local


::: {#lst-example-unzip-adminexpress lst-cap="2Ô∏è‚É£ D√©zipper la version t√©l√©charg√©e"}

```{python}
#| code-fold: true
#| code-summary: "2Ô∏è‚É£ D√©zipper la version t√©l√©charg√©e"
#| code-line-numbers: true
#| output: false

def extract_7z_archive(
    file_name, output_dir = "extracted_files"
):
    # Step 2: Extract the .7z file
    os.makedirs(output_dir, exist_ok=True)

    print("Extracting the file...")
    with py7zr.SevenZipFile(file_name, mode='r') as z:
        z.extractall(path=output_dir)
    print(f"Extracted to {output_dir}")
    return output_dir

extract_7z_archive(file_name)
```

:::

La troisi√®me √©tape consiste √† importer les fonds de carte d√©sir√©s. Le pi√®ge √† cette √©tape est qu'il existe deux fonds de carte d'arrondissements: les arrondissements d√©partementaux(subdivisions d√©partementales) et les arrondissements municipaux (subdivisions des trois plus grandes villes fran√ßaises). Ce sont ces derniers qui nous int√©ressent. Ils sont livr√©s sous le nom de fichier `ARRONDISSEMENT_MUNICIPAL` (√† ne pas confondre avec `ARRONDISSEMENT` qui correspond aux arrondissements d√©partementaux). 

Les donn√©es sont livr√©es au format _shapefile_, un format propri√©taire bien connu des sp√©cialistes des SIG. Moins pratique que le GeoJSON pour les utilisateurs de `Python`, il est tout de m√™me possible de le lire directement avec `GeoPandas`

::: {#lst-example-open-adminexpress lst-cap="3Ô∏è‚É£ Importer le bon shapefile dans Python"}

```{python}
#| code-fold: true
#| code-summary: "3Ô∏è‚É£ Importer le bon _shapefile_ dans Python"
#| code-line-numbers: true

path_extraction = "./extracted_files/ADMIN-EXPRESS-COG-CARTO_3-1__SHP_WGS84G_FRA_2022-04-15/ADMIN-EXPRESS-COG-CARTO/1_DONNEES_LIVRAISON_2022-04-15/ADECOGC_3-1_SHP_WGS84G_FRA/"

# Limites communales
city_shapefile = gpd.read_file(f"{path_extraction}/COMMUNE.shp")

# Arrondissements
arrondissement_shapefile = gpd.read_file(f"{path_extraction}/ARRONDISSEMENT_MUNICIPAL.shp")

# D√©partements
departements_shapefile = gpd.read_file(f"{path_extraction}/DEPARTEMENT.shp")
```

:::

La 4e et derni√®re √©tape, la plus propice √† faire des erreurs, est celle qui consiste √† restreindre les donn√©es √† notre aire d'int√©r√™t et √† superposer les masques du fonds des arrondissements municipaux avec celui des communes. 

::: {#lst-example-merge-adminexpress lst-cap="4Ô∏è‚É£ Consolider pour obtenir le fonds de carte d√©sir√©"}

```{python}
#| code-fold: true
#| code-summary: "4Ô∏è‚É£ Consolider pour obtenir le fonds de carte d√©sir√©"
#| code-line-numbers: true

import pandas as pd

# 1. Filtrer les donn√©es √† l'emprise d√©sir√©e
city_shapefile = city_shapefile.loc[
    city_shapefile['INSEE_DEP'].isin(["75", "92", "93", "94"])
]
arrondissement_shapefile = arrondissement_shapefile.loc[
    arrondissement_shapefile['INSEE_COM'].str[:2] == "75"
]

# 2. Pr√©parer la superposition des fonds de carte
city_shapefile = (
    city_shapefile
    .loc[city_shapefile["INSEE_DEP"] != "75"]
)
city_shapefile['INSEE_COG'] = city_shapefile['INSEE_COM'] #<1>
arrondissement_shapefile['INSEE_COG'] = arrondissement_shapefile['INSEE_COM'] #<1>
arrondissement_shapefile['INSEE_COM'] = "75056" #<2>

geodataframe_cartiflette_like = pd.concat(
    [city_shapefile, arrondissement_shapefile]
)
``` 
1. On cr√©e les variables `INSEE_COG` et `INSEE_COM` pour avoir des identifiants de localisation √©quivalents √† ceux de `cartiflette`
2. Code commune de la ville de Paris

:::

```{python}
#| echo: false
end_time_no_cartiflette = time.time()
```

# Bilan 

Si le fait qu'il suffise que le code de `cartiflette` se r√©duise √† @lst-cartiflette-example contre @lst-example-download-adminexpress, @lst-example-unzip-adminexpress, @lst-example-open-adminexpress, @lst-example-merge-adminexpress pour obtenir un r√©sultat √©quivalent ne suffit pas, si le fait que le _GeoDataFrame_ obtenu avec `cartiflette` comporte plus de m√©tadonn√©es que celui cr√©√© sans ce _package_ n'est pas non plus suffisant, la suite d√©roule quelques arguments suppl√©mentaires de l'int√©r√™t d'utiliser `cartiflette`. 


## Volume de donn√©es t√©l√©charg√©es

```{python}
#| code-fold: true
#| code-summary: "Fonction convert_size pour avoir les tailles de fichiers dans un format lisible par un humain"
# Convert to a human-readable format (e.g., MB, GB)
def convert_size(size_bytes):
    if size_bytes == 0:
        return "0B"
    size_name = ("B", "KB", "MB", "GB", "TB")
    i = int(math.floor(math.log(size_bytes, 1024)))
    p = math.pow(1024, i)
    s = round(size_bytes / p, 2)
    return f"{s} {size_name[i]}"
```


```{python}
#| code-fold: true
#| code-summary: "Evaluation de la taille des fichiers issus d'AdminExpress"
import math
import os
from pathlib import Path

# Path to the zipped file
zipped_file = "ADMIN-EXPRESS-COG-CARTO_3-1__SHP_WGS84G_FRA_2022-04-15.7z"

# Get the size of the zipped file in bytes
zipped_size = os.path.getsize(zipped_file)

# Path to the directory containing unzipped files
unzipped_dir = "./extracted_files"

root_directory = Path(unzipped_dir)
size_dir = sum(f.stat().st_size for f in root_directory.glob('**/*') if f.is_file())

poids_archive_compressee = convert_size(zipped_size)
poids_archive_decompressee = convert_size(size_dir)
```

```{python}
#| output: false
#| code-fold: true
#| code-summary: "Evaluation de la taille des m√™mes donn√©es issues de cartiflette"

writedir = "cartiflette-data/usecase1"
os.makedirs(writedir, exist_ok=True)
contours_villes_arrt.to_file(
    f"{writedir}/contours.shp"
) #<1>

poids_archive_cartiflette_bytes = os.path.getsize(f"{writedir}/contours.shp")
poids_archive_cartiflette = convert_size(
    poids_archive_cartiflette_bytes
)
```
1. On cr√©e un _shapefile_ avec le `GeoDataFrame` obtenu depuis `cartiflette` afin d'avoir une comparaison honn√™te avec le fonds de carte issu du site de l'IGN. 

La premi√®re base de comparaison possible est la taille sur disque des fonds de carte r√©cup√©r√©s par `cartiflette` ou sans passer par ce _package_. Le code ci-dessus ‚òùÔ∏è permet de construire les statistiques suivantes:

* Les donn√©es `cartiflette` repr√©senteraient __`{python} poids_archive_cartiflette`__ si elles √©taient stock√©es sur disque. 
* Sans passer par `cartiflette`, on a besoin de __`{python} poids_archive_decompressee`__ pour stocker les fonds de carte d√©compress√©s auxquels il faut ajouter `{python} poids_archive_compressee` pour stocker l'archive compress√©e. 

Autrement dit, les donn√©es r√©cup√©r√©es sans `cartiflette` repr√©sentent __`{python} round((zipped_size + size_dir)/poids_archive_cartiflette_bytes)` fois__ le volume de celles exclusivement n√©cessaires pour cette carte.

```{python}
#| echo: false
import glob

directory = "extracted_files"
file_list = glob.glob(f"{directory}/**/*", recursive=True)
# Filter out directories (we want to count only files)
file_list = [file for file in file_list if not os.path.isdir(file)]

nbre_fichiers = len(file_list)
```

L'arborescence du dossier d√©compress√© est √©galement assez cons√©quente: nous avons `{python} nbre_fichiers` fichiers. L'arborescence compl√®te obtenue sans `cartiflette` est disponible ci-dessous. Avec `cartiflette` aucun fichier n'est √©crit sur disque, tout est directement accessible dans la session `Python`.

<details>

<summary>
Arborescence compl√®te
</summary>

```{python}
#| echo: false
from directory_tree import DisplayTree
DisplayTree(directory)
```

</details>


## Nombre de lignes de code


::: {.content-visible when-format="html"}

```{ojs}
//| echo: false
md`La r√©cup√©ration des donn√©es avec \`cartiflette\` ne demande que __${nlines_cartiflette} lignes de code__ contre __${nlines_no_cartiflette} sans \`cartiflette\`__`
```

```{ojs}
//| echo: false
nlines_no_cartiflette = d3.sum(nrows_no_cartiflette)
```

```{ojs}
//| echo: false
nlines_cartiflette = d3.sum(nrows_cartiflette)
```

En ce qui concerne le temps de d√©veloppement de ce code, on est sur quelques secondes pour le code avec `cartiflette` en utilisant la [documentation interactive d'exemples](index.qmd) contre plusieurs dizaines de minutes pour le code sans `cartiflette`. 

:::

::: {.content-visible when-format="ipynb"}

La r√©cup√©ration des donn√©es avec cartiflette ne demande que 13 lignes de code contre 78 sans cartiflette

:::

## Temps de traitement 

```{python}
#| echo: false
import datetime

def human_readable_time(duration):
    # Convert the duration to seconds if it's not already
    if isinstance(duration, datetime.timedelta):
        total_seconds = int(duration.total_seconds())
    else:
        total_seconds = int(duration)
    
    hours, remainder = divmod(total_seconds, 3600)
    minutes, seconds = divmod(remainder, 60)

    if hours > 0:
        return f"{hours} heures, {minutes} minutes et {seconds} secondes"
    elif minutes > 0:
        return f"{minutes}minutes et {seconds} secondes"
    else:
        return f"{seconds} secondes"

time_cartiflette_exact = end_time_cartiflette - start_time_cartiflette
time_no_cartiflette_exact = end_time_no_cartiflette - start_time_no_cartiflette

time_cartiflette = human_readable_time(
    time_cartiflette_exact
)
time_no_cartiflette = human_readable_time(
    time_no_cartiflette_exact
)
```

Le code `cartiflette` permet de r√©cup√©rer les √©l√©ments contextuels n√©cessaires en `{python} time_cartiflette`. Sans `cartiflette`, il faut `{python} time_no_cartiflette`. Sans `cartiflette`, soit un rapport de 1 √† `{python} round(time_no_cartiflette_exact/time_cartiflette_exact)` pour cette t√¢che.

::: {.content-visible when-format="html"}

<!------------
Retrieve number of lines
-------------->

```{ojs}
//| echo: false
labels = [
    'lst-example-download-adminexpress',
    'lst-example-unzip-adminexpress',
    'lst-example-open-adminexpress',
    'lst-example-merge-adminexpres'
]
labels_cartiflette = [
    'lst-cartiflette-example'
]

function extractLineNumbers(label) {
    const selector = `[aria-describedby^="${label}"]`;
    const blocks = document.querySelectorAll(selector);

    let lineNumbers = [];

    blocks.forEach(block => {
        // Search for ids matching "annotated-cell-XX-N"
        const annotatedCells = block.querySelectorAll('[id^="annotated-cell-"]');
        annotatedCells.forEach(cell => {
            const match = cell.id.match(/annotated-cell-\d+-(\d+)/);
            if (match) {
                lineNumbers.push(parseInt(match[1], 10));
            }
        });

        // Search for ids matching "cbXX-N"
        const cbCells = block.querySelectorAll('[id^="cb"]');
        cbCells.forEach(cell => {
            const match = cell.id.match(/cb\d+-(\d+)/);
            if (match) {
                lineNumbers.push(parseInt(match[1], 10));
            }
        });
    });

    return lineNumbers;
}

function getMaxLineNumber(label) {
    const lineNumbers = extractLineNumbers(label);
    return Math.max(...lineNumbers);
}

// Iterate over labels to get max line numbers
nrows_no_cartiflette = labels.map(label => {
    const maxLineNumber = getMaxLineNumber(label);
    return maxLineNumber;
})

nrows_cartiflette = labels_cartiflette.map(label => {
    const maxLineNumber = getMaxLineNumber(label);
    return maxLineNumber;
})


```

:::