---
title: "Associer des arrondissements √† des donn√©es communales avec `cartiflette`"
output: true
number-sections: true
code-annotations: hover
---

::: {.callout-important}
Cette page est un _work in progress_! Des exemples dans d'autres langages que `Python` {{< fa brands python >}} viendront ult√©rieurement. 
:::


Ce tutoriel vise √† illustrer un cas d'usage classique de `cartiflette` : __r√©cup√©rer de mani√®re flexible un fonds de carte m√©langeant les niveaux administratifs diff√©rents que sont [communes]{.yellow} et [arrondissements]{.yellow}__.  

Ce besoin classique est illustr√© √† travers la construction d'une carte de la disponibilit√© de v√©libs dans la petite couronne parisienne (Paris intra-muros et d√©partements limitrophes). 
L'objectif de ce tutoriel est de faire une carte du nombre de v√©libs au km¬≤ dans chaque arrondissement de Paris intra-muros et chaque commune de la petite couronne.


::: {.callout-tip}
## Pourquoi utiliser `cartiflette` pour ce type de besoins ?

- Beaucoup [moins de ligne de code]{.yellow} √† √©crire :
    + R√©duit le temps n√©cessaire avant d'obtenir une carte exploratoire, ce qui permet de se concentrer sur la construction de celle-ci plut√¥t que les √©tapes ant√©rieures
    + R√©duit la difficult√© √† mettre √† jour le code ;
- [Moins de bande passante]{.yellow} et d'espace disque utilis√© car seule la donn√©e n√©cessaire est t√©l√©charg√©e ;
- [Moindre besoin d'expertise en SIG]{.yellow} car la librairie fournit un `GeoDataFrame` pr√™t √† l'emploi ce qui ne n√©cessite pas une connaissance pointue dans le domaine (syst√®me de projection, format _shapefile_, etc.) ;
- [Moins de risque d'erreur]{.yellow} que lorsqu'on fait soi-m√™me la combinaison de sources √† des niveaux administratifs diff√©rents (accoler le masque des arrondissements √† celui des communes limitrophes n√©cessite beaucoup de pr√©cautions) ;
- [B√©n√©ficier de m√©tadonn√©es suppl√©mentaires]{.yellow} sur les communes que les fonds de carte `AdminExpress`

:::


::: {.callout-note}
## Et Lyon et Marseille ?

`cartiflette` fournit le m√™me d√©coupage par arrondissement pour les villes de Lyon et Marseille. Pour cela, il suffit de demander une zone g√©ographique englobant Lyon et Marseille, par exemple le d√©partement du Rh√¥ne ou la r√©gion Provence Alpes C√¥te d'Azur. 

:::


::: {.callout-caution collapse="true"}
## Pour en apprendre plus sur le traitement de donn√©es g√©ographiques avec `Python` {{< fa brands python >}}

Ce tutoriel pr√©suppose une connaissance minimale de l'√©cosyst√®me `Python` pour le traitement de donn√©es spatiales. Pour se familiariser √† celui-ci, vous pouvez consulter ce cours d'[Introduction √† `Python` {{< fa brands python >}} pour la _data science_](https://pythonds.linogaliana.fr/content/manipulation/03_geopandas_intro.html) de l'ENSAE ParisTech. 

:::


# Pr√©liminaire: r√©cup√©ration des localisations des stations

Les donn√©es V√©lib que nous utiliserons sont r√©cup√©rables directement avec `GeoPandas`. Il s'agit de la capacit√© et la localisation des stations sous la forme de latitude-longitude[^WGS]

[^WGS]: Le syst√®me de coordonn√©es WGS84 (_World Geodetic System 1984_) est un syst√®me de r√©f√©rence g√©od√©sique utilis√© pour repr√©senter les positions g√©ographiques sur la Terre. Ce syst√®me est utilis√© par la plupart des applications GPS et des fournisseurs de tuiles vectorielles comme `OpenStreetMap`.


```{python}
import geopandas as gpd

velib_data = "https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr"
stations = gpd.read_file(velib_data)
```

Ces donn√©es prennent la forme suivante:

```{python}
#| echo: false
stations.head(2)
```

et peuvent √™tre localis√©es sur une carte de la mani√®re suivante:

```{python}
#| output: false
#| code-fold: true
#| code-summary: "Voir le code pour g√©n√©rer la carte interactive üëáÔ∏è"
import folium
from folium.plugins import MarkerCluster

# 1. Calcul du centre de la carte et des bornes sw et ne
stations['lon'] = stations.geometry.x
stations['lat'] = stations.geometry.y
center = stations[['lat', 'lon']].mean().values.tolist()
sw = stations[['lat', 'lon']].min().values.tolist()
ne = stations[['lat', 'lon']].max().values.tolist()

m = folium.Map(location=center, tiles='OpenStreetMap')
marker_cluster = MarkerCluster().add_to(m) #<1>

# Add the markers to the MarkerCluster
for i in range(len(stations)):
    folium.Marker(
        location=[stations.iloc[i]['lat'], stations.iloc[i]['lon']],
        popup=stations.iloc[i]['name']
    ).add_to(marker_cluster)

# Fit the map bounds to the markers
m.fit_bounds([sw, ne])
m
```
1. Cette fonctionnalit√© permet d'avoir une carte interactive avec zoom progressifs car le nombre de stations est important ce qui ralentirait la carte de toutes les afficher 


```{python}
#| echo: false
m
```

<br>
Nous allons avoir besoin des contours d'arrondissements et de communes pour deux raisons:

- Localiser les stations √† ce niveau d'analyse par le biais d'une [jointure spatiale](https://geopandas.org/en/stable/gallery/spatial_joins.html) avant de pouvoir les agr√©ger √† ce niveau ;
- Repr√©senter ces donn√©es sur une carte pr√©sentant Paris intra-muros et les villes limitrophes participant au syst√®me V√©lib.


# R√©cup√©rer les contours administratifs officiels l'IGN via `cartiflette`

## La r√©cup√©ration des donn√©es utilisant `cartiflette`

```{python}
#| echo: false
import time
start_time_cartiflette = time.time()
```

Les contours administratifs officiels sont produits par l'[IGN](https://www.ign.fr/) et utilisent le [code officiel g√©ographique (COG)](https://www.insee.fr/fr/metadonnees/source/serie/s2084) (liste officielle des entit√©s administratives) produit par l'Insee. 

La source la plus simple pour r√©pondre √† notre besoin est [`AdminExpress EXPRESS-COG-CARTO-TERRITOIRE`](https://geoservices.ign.fr/adminexpress). En l'occurrence, seuls quelques espaces nous int√©ressent: ce sont les villes et arrondissements de la petite couronne parisienne (d√©partements 75, 92, 93 et 94). 

Avec la fonction `carti_download`, l'import de ces donn√©es est assez transparent:

```{python}
#| code-line-numbers: true
from cartiflette import carti_download

# 1. Fonds communaux
contours_villes_arrt = carti_download(
    values = ["75", "92", "93", "94"],
    crs = 4326, #<1>
    borders="COMMUNE_ARRONDISSEMENT",
    filter_by="DEPARTEMENT", #<2>
    source="EXPRESS-COG-CARTO-TERRITOIRE",
    year=2022)


# 2. D√©partements 
departements = contours_villes_arrt.dissolve("INSEE_DEP") #<3>
```
1. 4326 est le code du syst√®me de repr√©sentation WGS84 (le m√™me que celui des donn√©es V√©lib). De futures d√©veloppement de `cartiflette` permettront de r√©cup√©rer des donn√©es avec d'autres projections, notamment les syst√®mes Lambert.
2. Ici on r√©cup√®re seulement des d√©partements, l'emprise la plus petite qui puisse satisfaire notre besoin. N√©anmoins, il serait possible d'obtenir les donn√©es √† une autre √©chelle g√©ographique, par exemple la r√©gion Ile de France, en sp√©cifiant les arguments `filter_by="DEPARTEMENT"` et `values="11"`.
3. La construction du fonds de carte `departements` se fait simplement avec la m√©thode `dissolve`. Il nous sera utile pour contextualiser la carte. 

```{python}
#| echo: false
end_time_cartiflette = time.time()
```

`contours_villes_arrt` est un `GeoDataFrame` classique, il est donc possible d'appliquer √† celui-ci les m√©thodes usuelles de `GeoPandas` par exemple la m√©thode `dissolve` ci-dessus. Le masque obtenu pour notre carte est celui-ci

```{python}
contours_villes_arrt.plot()
```

Pour voir le code permettant d'obtenir un `GeoDataFrame` √©quivalent sans passer par `cartiflette`, vous pouvez vous rendre dans la partie [Comment faire sans `cartiflette` ?](#sans-cartiflette). La section [Bilan](#bilan) fournit quelques √©l√©ments de comparaison entre l'approche avec et celle sans `cartiflette` (temps de traitement, volume de donn√©es t√©l√©charg√©es, nombre de lignes de codes, etc.). 


## Le reste du travail apr√®s avoir utilis√© `cartiflette`

La suite du travail n'est pas li√© √† `cartiflette` mais est de la manipulation de donn√©es spatiales. 

Comme nous avons besoin de localiser les stations dans les arrondissements, nous faisons une jointure spatiale entre notre fonds de carte et nos donn√©es V√©lib

```{python}
stations_info = gpd.sjoin(
    stations, contours_villes_arrt, predicate="within"
)
```

Outre la localisation des stations au niveau communes ou arrondissement, cela permet d'ajouter une ribambelle de m√©tadonn√©es (des informations annexes) √† nos donn√©es initiales:

```{python}
#| echo: false
stations_info.head(2)
```

Le d√©compte des stations par communes et arrondissements se fait alors assez ais√©ment en utilisant la grammaire `Pandas`. Pour cela, il est possible d'utiliser la variable `INSEE_COG` construite par `cartiflette` pour consolider les codes communes des arrondissements et des communes[^inseeCOM]

[^inseeCOM]: La variable `INSEE_COM` correspond au code officiel g√©ographique au niveau communal. La valeur est donc identique pour les 20 arrondissements parisiens.  

```{python}
comptes = (
    stations_info
    .groupby("INSEE_COG")
    .agg({"capacity": "sum"})
    .reset_index()
)
```

Enfin, il ne reste plus qu'√† construire la variable d'int√©r√™t, ce qui n'est pas du travail li√© √† `cartiflette`:

```{python}
#| code-fold: true
#| code-summary: "D√©rouler üëáÔ∏è pour voir le code permettant pr√©parer la carte"
#| output: false
import pandas as pd

# Conversion des variables
contours_villes_arrt["INSEE_COG"] = contours_villes_arrt["INSEE_COG"].astype(str) #<1>
comptes["INSEE_COG"] = comptes["INSEE_COG"].astype(str) #<1>

# Jointure pour retrouver la dimension g√©ographique de nos donn√©es agr√©g√©es
comptes_velib_by_city_arrt = contours_villes_arrt.merge(
    comptes, how = "inner", on = "INSEE_COG"
)
comptes_velib_by_city_arrt['densite'] = comptes_velib_by_city_arrt['capacity']

# Cr√©ation des variables pour la taille de nos ronds proportionnels
df_points = comptes_velib_by_city_arrt.copy()

df_points["markersize"] = 12*df_points["densite"].div(comptes_velib_by_city_arrt.to_crs(2154).area.div(10**6).sum())

bins = [-float('inf'), 20, 100, 500, float('inf')]
labels = ["Moins de 20", "Entre 20 et 100", "Entre 100 et 500", "Plus de 500"]

df_points["markercolor"] = pd.cut(
    df_points['densite'], bins=bins, labels=labels, right=True
)

# Centre de nos cercles
df_points["geometry"] = df_points["geometry"].centroid
```
1. On force la conversion de la variable `INSEE_COG` en _string_ pour √©viter le type `object` de `Pandas` qui peut poser des probl√®mes lors des jointures. 

Finalement, on obtient la carte avec le code suivant

```{python}
#| code-fold: true
#| code-summary: "D√©rouler üëáÔ∏è pour voir le code permettant de faire la carte"
import matplotlib.pyplot as plt

ax = comptes_velib_by_city_arrt.plot(
    color="lightgray", edgecolor="grey", figsize=(7, 7), linewidth=0.4, alpha=0.3
)
df_points.plot(
    ax=ax,
    column="markercolor",
    markersize="markersize",
    alpha=0.7,  # categorical=False,
    legend=True,
    legend_kwds={"loc": "upper center", "ncol": 2, "bbox_to_anchor": (0.5, 0.05)},
    cmap="viridis",
)
departements.boundary.plot(ax=ax, edgecolor="black", alpha=0.3)
ax.axis("off")
ax.set(title="Densit√© de population dans la petite couronne")
ax.get_legend().set_title("Nombre de v√©lib par km¬≤")
plt.figtext(
    0.3,
    0.15,
    "Source: IGN - AdminExpress",
    wrap=True,
    horizontalalignment="center",
    fontsize=8,
    style="italic",
)
```

# Comment faire sans `cartiflette` ? {.sans-cartiflette}

```{python}
#| echo: false
start_time_no_cartiflette = time.time()
```

L'approche est nettement plus fastidieuse sans `cartiflette`. Pour obtenir les m√™mes donn√©es, pr√™tes √† l'emploi, cela passe par quatre √©tapes principales:

* 1Ô∏è‚É£ T√©l√©charger les donn√©es et les enregistrer sur le disque, en local.
* 2Ô∏è‚É£ D√©zipper la version t√©l√©charg√©e (le format est une archive 7z) et enregistrer l'arborescence obtenue sur le disque.
* 3Ô∏è‚É£ Importer les bons _shapefile_ dans `Python`.
* 4Ô∏è‚É£ Cr√©er le fonds de carte consolid√© en se restreignant aux d√©partements d'int√©r√™t pouis en retirant la commune de Paris et en y apposant, √† la place, les arrondissements.

La premi√®re √©tape consiste donc √† t√©l√©charger le fichier depuis le site de mise √† disposition de l'IGN. L'archive √©tant assez volumineuse, le code propos√© propose une barre de progr√®s pour s'assurer que le t√©l√©chargement progresse.

Le code √©tant assez long, il n'est pas apparent par d√©faut mais il suffit de cliquer ci-dessous:

```{python}
#| code-fold: true
#| code-summary: "1Ô∏è‚É£ Code pour t√©l√©charger les donn√©es"
#| code-line-numbers: true
#| output: false

import os
import requests
import py7zr
from tqdm import tqdm

# Step 1: Download the file with progress bar
url = "https://data.geopf.fr/telechargement/download/ADMIN-EXPRESS-COG-CARTO/ADMIN-EXPRESS-COG-CARTO_3-1__SHP_WGS84G_FRA_2022-04-15/ADMIN-EXPRESS-COG-CARTO_3-1__SHP_WGS84G_FRA_2022-04-15.7z"
file_name = url.split("/")[-1]

def download_7z_archive(file_name):
    if os.path.exists(file_name) is False:
        # Streaming download with progress bar
        print("Downloading file...")
        response = requests.get(url, stream=True)
        total_size = int(response.headers.get('content-length', 0))

        with open(file_name, 'wb') as file, tqdm(
                desc=file_name,
                total=total_size,
                unit='iB',
                unit_scale=True,
                unit_divisor=1024,
            ) as bar:
            for chunk in response.iter_content(chunk_size=8192):
                size = file.write(chunk)
                bar.update(size)

        print(f"Downloaded {file_name}")
        return file_name
    else:
        print("File exists, please delete it before going further")

download_7z_archive(file_name)
```

La deuxi√®me √©tape consiste √† d√©zipper la version t√©l√©charg√©e en local

```{python}
#| code-fold: true
#| code-summary: "2Ô∏è‚É£ D√©zipper la version t√©l√©charg√©e"
#| code-line-numbers: true
#| output: false

def extract_7z_archive(
    file_name, output_dir = "extracted_files"
):
    # Step 2: Extract the .7z file
    os.makedirs(output_dir, exist_ok=True)

    print("Extracting the file...")
    with py7zr.SevenZipFile(file_name, mode='r') as z:
        z.extractall(path=output_dir)
    print(f"Extracted to {output_dir}")
    return output_dir

extract_7z_archive(file_name)
```

La troisi√®me √©tape consiste √† importer les fonds de carte d√©sir√©s. Le pi√®ge √† cette √©tape est qu'il existe deux fonds de carte d'arrondissements: les arrondissements d√©partementaux(subdivisions d√©partementales) et les arrondissements municipaux (subdivisions des trois plus grandes villes fran√ßaises). Ce sont ces derniers qui nous int√©ressent. Ils sont livr√©s sous le nom de fichier `ARRONDISSEMENT_MUNICIPAL` (√† ne pas confondre avec `ARRONDISSEMENT` qui correspond aux arrondissements d√©partementaux). 

Les donn√©es sont livr√©es au format _shapefile_, un format propri√©taire bien connu des sp√©cialistes des SIG. Moins pratique que le GeoJSON pour les utilisateurs de `Python`, il est tout de m√™me possible de le lire directement avec `GeoPandas`

```{python}
#| code-fold: true
#| code-summary: "3Ô∏è‚É£ Importer le bon _shapefile_ dans Python"
#| code-line-numbers: true
path_extraction = "./extracted_files/ADMIN-EXPRESS-COG-CARTO_3-1__SHP_WGS84G_FRA_2022-04-15/ADMIN-EXPRESS-COG-CARTO/1_DONNEES_LIVRAISON_2022-04-15/ADECOGC_3-1_SHP_WGS84G_FRA/"

# Limites communales
city_shapefile = gpd.read_file(f"{path_extraction}/COMMUNE.shp")

# Arrondissements
arrondissement_shapefile = gpd.read_file(f"{path_extraction}/ARRONDISSEMENT_MUNICIPAL.shp")

# D√©partements
departements_shapefile = gpd.read_file(f"{path_extraction}/DEPARTEMENT.shp")
```

La 4e et derni√®re √©tape, la plus propice √† faire des erreurs, est celle qui consiste √† restreindre les donn√©es √† notre aire d'int√©r√™t et √† superposer les masques du fonds des arrondissements municipaux avec celui des communes. 

```{python}
#| code-fold: true
#| code-summary: "3Ô∏è‚É£ Importer le bon _shapefile_ dans Python"
#| code-line-numbers: true
import pandas as pd

# 1. Filtrer les donn√©es √† l'emprise d√©sir√©e
city_shapefile = city_shapefile.loc[
    city_shapefile['INSEE_DEP'].isin(["75", "92", "93", "94"])
]
arrondissement_shapefile = arrondissement_shapefile.loc[
    arrondissement_shapefile['INSEE_COM'].str[:2] == "75"
]

# 2. Pr√©parer la superposition des fonds de carte
city_shapefile = (
    city_shapefile
    .loc[city_shapefile["INSEE_DEP"] != "75"]
)
city_shapefile['INSEE_COG'] = city_shapefile['INSEE_COM'] #<1>
arrondissement_shapefile['INSEE_COG'] = arrondissement_shapefile['INSEE_COM'] #<1>
arrondissement_shapefile['INSEE_COM'] = "75056" #<2>

geodataframe_cartiflette_like = pd.concat(
    [city_shapefile, arrondissement_shapefile]
)
``` 
1. On cr√©e les variables `INSEE_COG` et `INSEE_COM` pour avoir des identifiants de localisation √©quivalents √† ceux de `cartiflette`
2. Code commune de la ville de Paris

```{python}
#| echo: false
end_time_no_cartiflette = time.time()
```

## Bilan 

## Volume de donn√©es t√©l√©charg√©es



### Nombre de lignes de code

### Temps de traitement 

En premier lieu, 

```{python}
#| echo: false
directory = "extracted_files"  # Change this to the path where your files are extracted
from directory_tree import DisplayTree
DisplayTree(directory)
```

nombre de fichiers

```{python}
import glob

# List all files recursively using glob
file_list = glob.glob(f"{directory}/**/*", recursive=True)

# Filter out directories (we want to count only files)
file_list = [file for file in file_list if not os.path.isdir(file)]

len(file_list)
```

volume sur disque: zipp√© et d√©zipp√©


```{python}
import os
import math

# Path to the zipped file
zipped_file = "ADMIN-EXPRESS-COG-CARTO_3-1__SHP_WGS84G_FRA_2022-04-15.7z"

# Get the size of the zipped file in bytes
zipped_size = os.path.getsize(zipped_file)

# Convert to a human-readable format (e.g., MB, GB)
def convert_size(size_bytes):
    if size_bytes == 0:
        return "0B"
    size_name = ("B", "KB", "MB", "GB", "TB")
    i = int(math.floor(math.log(size_bytes, 1024)))
    p = math.pow(1024, i)
    s = round(size_bytes / p, 2)
    return f"{s} {size_name[i]}"

print(f"Zipped file size: {convert_size(zipped_size)}")
```


```{python}
from pathlib import Path

# Path to the directory containing unzipped files
unzipped_dir = "./extracted_files"

root_directory = Path(unzipped_dir)
size_dir = sum(f.stat().st_size for f in root_directory.glob('**/*') if f.is_file())
convert_size(size_dir)
```

